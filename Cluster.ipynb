{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-13 21:35:00.475508\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt  \n",
    "import seaborn as sns\n",
    "from matplotlib.ticker import AutoMinorLocator, MultipleLocator\n",
    "from tqdm import tqdm\n",
    "from sklearn.decomposition import PCA\n",
    "from kneed import DataGenerator, KneeLocator\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn import metrics\n",
    "from datetime import datetime\n",
    "import time\n",
    "plt.rcParams['font.family'] = \"Times New Roman\"\n",
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset loading\n",
    "l1 = [\"\",\"RMSD_4ey4_1.csv\",\"RMSD_4ey5_1.csv\",\"RMSD_4ey6_1.csv\",\"RMSD_4ey7_1.csv\"]\n",
    "l2 = [\"\",\"4ey4\",\"4ey5\",\"4ey6\",\"4ey7\"]\n",
    "for i in range(1,5,1):\n",
    "    globals()['d'+str(i)] = pd.read_csv(l1[i])\n",
    "    globals()['X'+str(i)] = globals()['d'+str(i)].iloc[:,1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA\n",
    "file = open(\"./data/log.txt\",'w')\n",
    "pca = PCA(n_components = 5)\n",
    "for i in range(1,5,1):\n",
    "    globals()['X_'+str(i)] = pca.fit_transform(globals()['X'+str(i)])\n",
    "    file.write(l1[i][0:-4])\n",
    "    file.write(f'\\nX_{str(i)}')\n",
    "    file.write(f'\\npca.explained_variance_ratio sum of 5 features : {(sum(pca.explained_variance_ratio_*100))}' )\n",
    "    file.write(f'\\nExplainedratio of indicidua  components : {pca.explained_variance_ratio_*100}')\n",
    "    file.write('\\n--------------------------------------------------------\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#K_mean\n",
    "from sklearn.cluster import KMeans \n",
    "fig, ax = plt.subplots()\n",
    "plt.xlabel(\"Value of K\") \n",
    "plt.ylabel(\"Sqaured Error (Cost)\") \n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "plt.xticks(np.arange(0, 25, step=1))\n",
    "color =['black','red', 'blue', 'orange', 'green']\n",
    "for i in tqdm(range(1,5,1)):\n",
    "    globals()['cost_'+str(i)] =[] \n",
    "    for j in range(1, 26): \n",
    "        Km = KMeans(n_clusters = j) \n",
    "        Km.fit(globals()['X_'+str(i)]) \n",
    "        globals()['cost_'+str(i)].append(Km.inertia_)        \n",
    "    time.sleep(0.5)\n",
    "    \n",
    "    plt.plot(range(1, 26), globals()['cost_'+str(i)], color = color[i], linewidth ='2')\n",
    "    kneedle = KneeLocator(range(1, 26), globals()['cost_'+str(i)], S=1.0, curve=\"convex\", direction=\"decreasing\")\n",
    "    file.write(l1[i][0:-4])\n",
    "    file.write(f\"\\nThe selected value of K is {(round(kneedle.knee, 3))} \\n\")\n",
    "    v1 = (round(kneedle.knee, 3))\n",
    "    Km = KMeans(n_clusters = v1) \n",
    "    Km.fit(globals()['X_'+str(i)]) \n",
    "    labels = Km.labels_\n",
    "    score1 = silhouette_score(globals()['X_'+str(i)], labels)\n",
    "    score2 = metrics.calinski_harabasz_score(globals()['X_'+str(i)], labels)\n",
    "    score3 = metrics.davies_bouldin_score(globals()['X_'+str(i)], labels)\n",
    "    file.write(f\"The slihoutte value for {v1} is silhoette score: {(round(score1, 3))}, calinski_harabasz score: {(round(score2, 3))},\\\n",
    "davies_bouldin score: {(round(score3, 3))} \\n\")\\\n",
    "    \n",
    "plt.savefig('./data/kmean.jpeg', dpi = 600)\n",
    "plt.show() # clear the plot \n",
    "\n",
    "\n",
    "file.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "neigh = NearestNeighbors(n_neighbors=2)\n",
    "for i in range(1,5,1):\n",
    "    nbrs = neigh.fit(globals()['X_'+str(i)])\n",
    "    distances, indices = nbrs.kneighbors(globals()['X_'+str(i)] )\n",
    "    distances = np.sort(distances, axis=0)\n",
    "    distances = distances[:,1]\n",
    "    plt.plot(distances)\n",
    "plt.savefig('knn.jpeg')\n",
    "plt.show() # clear the plot \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [08:44<00:00, 87.37s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [08:59<00:00, 89.89s/it]\n",
      " 17%|█████████████▊                                                                     | 1/6 [02:31<12:35, 151.17s/it]"
     ]
    }
   ],
   "source": [
    "#DBSCAN\n",
    "df2 = pd.DataFrame()\n",
    "from sklearn.cluster import DBSCAN\n",
    "list1 = ['cityblock', 'cosine', 'euclidean', 'l1', 'l2', 'manhattan']\n",
    "list2 = np.arange(0.10 ,1.6, 0.10)\n",
    "list3 = [5,10,15,20,25,30,40,50]\n",
    "for i1 in range(1,5,1):\n",
    "    df2 = pd.DataFrame()\n",
    "    for i in tqdm(list1):\n",
    "        df3 = pd.DataFrame()\n",
    "        for j in list2:\n",
    "            for k in list3:\n",
    "                clustering = DBSCAN(eps = j, min_samples = k, metric =i)\n",
    "                labels = clustering.fit_predict(globals()['X_'+str(i1)])\n",
    "                nCluster = len(set(labels))-(1 if -1 in labels else 0)\n",
    "                n_noise = list(labels).count(-1)\n",
    "                if nCluster == 1 or nCluster == 0:\n",
    "                    df2 = df2.append({'Distance Metric': i, 'epsilon': round(j,2), 'Number of samples':int(k), 'Silhouette coefficient': -1, 'Number of clusters' : nCluster, \"Noise\": n_noise}, ignore_index = True)\n",
    "                    df3 = df3.append({'Distance Metric': i, 'epsilon': round(j,2), 'Number of samples':int(k), 'Silhouette coefficient': -1, 'Number of clusters' : nCluster, \"Noise\": n_noise}, ignore_index = True)\n",
    "                else:\n",
    "                    score = silhouette_score(X1, labels, metric=i)\n",
    "                    df2 = df2.append({'Distance Metric': i, 'epsilon': round(j,2), 'Number of samples':int(k), 'Silhouette coefficient': round(score,3), 'Number of clusters' : nCluster, \"Noise\": n_noise}, ignore_index = True)\n",
    "                    df3 = df3.append({'Distance Metric': i, 'epsilon': round(j,2), 'Number of samples':int(k), 'Silhouette coefficient': round(score,3), 'Number of clusters' : nCluster, \"Noise\": n_noise}, ignore_index = True)\n",
    "        df3_ = df3[['epsilon', 'Number of samples', 'Silhouette coefficient']]\n",
    "        heatmap1_data = pd.pivot_table(df3_, values='Silhouette coefficient' ,index=['Number of samples'], columns='epsilon')\n",
    "        sns.set()\n",
    "        ob = sns.color_palette(\"pastel\", as_cmap=True)\n",
    "        #plt.figure(figsize = (4.0, 4.0))\n",
    "        sns.heatmap(heatmap1_data, cmap= ob, annot=True, fmt=\".2f\", annot_kws={'size':7},\\\n",
    "             cbar=False, square=True,  linewidths=1, linecolor='white')\n",
    "        plt.xlabel('epsilon', size = 11)\n",
    "        plt.ylabel('Number of samples', size = 11)\n",
    "        plt.xticks(fontsize=8)\n",
    "        plt.yticks(fontsize=8,rotation='horizontal')\n",
    "        plt.title(str(l2[i1]) + ' and ' + str(i), size = 12)\n",
    "        plt.savefig('./data/{}_{}.jpeg'.format(l2[i1], i),dpi =600, format ='jpeg')\n",
    "        plt.close()\n",
    "    \n",
    "    str1 = './data/'+l2[i1]+'_Dbscan.csv'\n",
    "                    \n",
    "    df2.to_csv(str1, mode ='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df2.nlargest(25,[\"Silhouette\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agglomerative clustering\n",
    "df3 = pd.DataFrame()\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "list2 = [ 'euclidean', 'l1', 'l2', 'manhattan','cosine']\n",
    "list3 = ['ward', 'average', 'complete', 'single']\n",
    "for j in tqdm(list2):\n",
    "    for k in list3:\n",
    "        for i in range(2, 26,1):\n",
    "            #print(i,j,k)\n",
    "            if j == 'l1' or j == 'l2' or j == 'manhattan' or j == 'cosine' and k == 'ward':\n",
    "                df3 = df3.append({'clusters': i, 'connectivity': j, 'linkage':k, 'Silhouette': -1}, ignore_index = True)\n",
    "            else:\n",
    "                clustering = AgglomerativeClustering(n_clusters= i, affinity = j, linkage= k)\n",
    "                labels = clustering.fit_predict(X1)\n",
    "            #nCluster = len(set(labels))-(1 if -1 in labels else 0)\n",
    "            if len(np.unique(labels)) == 1:\n",
    "                df3 = df3.append({'clusters': i, 'connectivity': j, 'linkage':k, 'Silhouette': -1}, ignore_index = True)\n",
    "            else:\n",
    "                score = silhouette_score(X1, labels, metric=j)\n",
    "                df3 = df3.append({'clusters': i, 'connectivity': j, 'linkage':k,  'Silhouette': round(score,3)}, ignore_index = True)\n",
    "                \n",
    "df3.to_csv('sil3.csv', mode ='w')\n",
    "print(df3.nlargest(20,[\"Silhouette\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AffinityPropagation\n",
    "sc = []\n",
    "for i in tqdm([0.5,0.6,0.7,0.8,0.9, 0.95]):\n",
    "    af = AffinityPropagation(damping = i, max_iter = 1000).fit(X1)\n",
    "    cluster_centers_indices = af.cluster_centers_indices_\n",
    "    labels = af.labels_\n",
    "    if len(np.unique(labels)) == 1:\n",
    "        pass\n",
    "    else:\n",
    "        score = round(silhouette_score(X1, labels),3)\n",
    "        sc.append(score)\n",
    "        nCluster = len(set(labels))-(1 if -1 in labels else 0)\n",
    "        print(nCluster)\n",
    "        print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spectral Clusterig\n",
    "df3 = pd.DataFrame()\n",
    "from sklearn.cluster import SpectralClustering\n",
    "\n",
    "for i in tqdm(range(2, 26,1)):\n",
    "    clustering = SpectralClustering(n_clusters=i,\n",
    "        assign_labels=\"discretize\",\n",
    "        random_state=0).fit(X1)\n",
    "    labels = clustering.labels_\n",
    "    nCluster = len(set(labels))-(1 if -1 in labels else 0)\n",
    "    score = silhouette_score(X1, labels, metric=j)\n",
    "    df3 = df3.append({'clusters': nCluster, 'Silhouette': round(score,3)}, ignore_index = True)\n",
    "                \n",
    "df3.to_csv('sil_spc.csv', mode ='w')\n",
    "print(df3.nlargest(20,[\"Silhouette\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#meanshift Clusterig\n",
    "df3 = pd.DataFrame()\n",
    "from sklearn.cluster import MeanShift\n",
    "\n",
    "for i in tqdm(np.arange(0.1,2,0.1)):\n",
    "    clustering = MeanShift(bandwidth=i).fit(X1)\n",
    "    labels = clustering.labels_\n",
    "    nCluster = len(set(labels))-(1 if -1 in labels else 0)\n",
    "    if nCluster >1 :\n",
    "        score = silhouette_score(X1, labels, metric=j)\n",
    "        df3 = df3.append({'clusters': nCluster, \"bandwiidth\": i, 'Silhouette': round(score,3)}, ignore_index = True)\n",
    "    else: \n",
    "        pass\n",
    "df3.to_csv('sil_mesh.csv', mode ='w')\n",
    "print(df3.nlargest(20,[\"Silhouette\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the cost against K values \n",
    "cost = df3['Silhouette']\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.plot(np.arange(0.1,2,0.1), cost, color ='b', linewidth ='3') \n",
    "plt.xlabel(\"Value of K\") \n",
    "plt.ylabel(\"Sqaured Error (Cost)\") \n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "plt.xticks(np.arange(0.1,2, step = 0.1))\n",
    "plt.show() # clear the plot \n",
    "kneedle = KneeLocator(np.arange(0.1,2,0.1), cost, S=1.0, curve=\"convex\", direction=\"decreasing\")\n",
    "print(\"The selected value of K is {}\".format(round(kneedle.knee, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BRICH clustering\n",
    "df3 = pd.DataFrame()\n",
    "from sklearn.cluster import Birch\n",
    "\n",
    "for i in tqdm(range(2, 26,1)):\n",
    "    clustering = Birch(n_clusters=i).fit(X1)\n",
    "    labels = clustering.predict(X1)\n",
    "    nCluster = len(set(labels))-(1 if -1 in labels else 0)\n",
    "    score = silhouette_score(X1, labels, metric=j)\n",
    "    df3 = df3.append({'clusters': nCluster, 'Silhouette': round(score,3)}, ignore_index = True)\n",
    "                \n",
    "df3.to_csv('sil_spc.csv', mode ='w')\n",
    "print(df3.nlargest(20,[\"Silhouette\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the cost against K values \n",
    "cost = df3['Silhouette']\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.plot(range(2,26,1), cost, color ='b', linewidth ='3') \n",
    "plt.xlabel(\"Value of K\") \n",
    "plt.ylabel(\"Sqaured Error (Cost)\") \n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "plt.xticks(range(2,26,1))\n",
    "plt.show() # clear the plot \n",
    "kneedle = KneeLocator(range(2,26,1), cost, S=1.0, curve=\"convex\", direction=\"decreasing\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library & dataset\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# create data\n",
    "x = np.random.rand(15)\n",
    "y = x+np.random.rand(15)\n",
    "z = x+np.random.rand(15)\n",
    "z=z*z\n",
    "\n",
    "sns.color_palette(\"pastel\", as_cmap = True)\n",
    "# You can reverse it:\n",
    "plt.scatter(x, y, s=z*2000, c=x,  alpha=0.4, edgecolors=\"grey\", linewidth=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str1 = './data/'+l2[i1]+'_Dbscan.csv'\n",
    "print(str1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
